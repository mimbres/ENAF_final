# Copyright (c) Cochlear.ai, Inc. and its affiliates.
#
# This source code is licensed under the MIT license found in the
# LICENSE file in the root directory of this source tree.
""".

Created on Tue Oct 27 15:14:32 2020

USAGE:
    CUDA_VISIBLE_DEVICES=0 python train_context_120_seq5_win1_ovrp05_zr_inmask_add_simclr.py <opt1:(str)EXP_NAME> <opt2:(int)EPOCH> <opt3:(str)TEST_MODE>

OPTIONS:
    - If <opt1:EXP_NAME> is given and pretrained model exists:
        - If <opt2> is empty, it continues training from the latest checkpoint.
        - Else if <opt2> is given, it continues training from the <opt2:EPOCH>.
    - If <opt1:EXP_NAME> is given and pretrained model doesn't exist, fresh start training.
    - If <opt1:EXP_NAME> is not given, EXP_NAME will be generated by dd/hh/mm/ss.
    - If <opt1>, <opt2> and <opt3:TEST_MODE> are given:
        - If <opt3:TEST_MODE> == "mini-test-only", it loads pre-trained model and proceed in-memory-search-mini-test, then quit.
        - If <opt3:TEST_MODE> == "save-db", it loads pre-trained model and only saves embeddings for DB as a numpy file.
        - If <opt3:TEST_MODE> == "save-db-query", it loads pre-trained model and saves embeddings for DB and Query as numpy files.
LOG-DIRECTORIES:
    
CUDA_VISIBLE_DEVICES=5 python sp_train_context_240_seq5_win1_ovrp05_zr_inmask_multi_loss_c1z0s1-1010_lamb.py exp_context_240_seq5_win1_ovrp05_zr_inmask_multi_loss_c1z0s1-1010_lamb
CUDA_VISIBLE_DEVICES=5 python sp_train_context_240_seq5_win1_ovrp05_zr_inmask_multi_loss_c1z0s1-1010_lamb.py exp_context_240_seq5_win1_ovrp05_zr_inmask_multi_loss_c1z0s1-1010_lamb '100' save-db-query 100k_full 
CUDA_VISIBLE_DEVICES=4 OMP_NUM_THREADS=12 python eval_faiss.py gpu logs/emb/exp_context_240_seq5_win1_ovrp05_zr_inmask_multi_loss_c1z0s1-1010_lamb/100/100k_full 2000 ivfpq-rr 20

---------ArgMin g(f(x)) mini-TEST----------
scope:   [1, 3, 5, 9, 11, 19]
T1acc: 82.43  94.92  97.28  98.46  98.88  100.00
mrank: 1.87  0.10  0.05  0.02  0.01  0.00
-----------ArgMin f(x) mini-TEST-----------
scope:   [1, 3, 5, 9, 11, 19]
T1acc: 79.79  92.98  95.33  97.49  98.25  99.51
mrank: 9.18  4.68  2.26  0.25  0.03  0.00
---------ArgMin l2(f(x)) mini-TEST---------
scope:   [1, 3, 5, 9, 11, 19]
T1acc: 79.93  92.98  95.26  97.42  98.18  99.44
mrank: 9.30  4.72  2.33  0.30  0.03  0.01

MIREX
matched_exact=[ 4.94 10.6  13.12 14.73 14.93 15.54]%, scope=[1, 3, 5, 9, 11, 19]
matched_near=[20.18 37.84 44.3  52.47 55.2  59.54]%, scope=[1, 3, 5, 9, 11, 19]
matched_song=[21.59 39.66 45.71 53.48 55.7  60.14]%, scope=[1, 3, 5, 9, 11, 19]

10k
matched_exact=[65.8  91.36 95.53 97.59 98.19 98.9 ]%, scope=[1, 3, 5, 9, 11, 19]
matched_near=[67.2  91.36 95.63 97.59 98.19 98.9 ]%, scope=[1, 3, 5, 9, 11, 19]
matched_song=[75.39 94.27 96.94 98.04 98.44 99.  ]%, scope=[1, 3, 5, 9, 11, 19]

100k_full
matched_exact=[37.42 66.3  74.79 82.62 84.38 88.05]%, scope=[1, 3, 5, 9, 11, 19]
matched_near=[37.82 66.5  74.84 82.62 84.38 88.05]%, scope=[1, 3, 5, 9, 11, 19]
matched_song=[48.32 74.38 81.32 85.94 86.99 89.6 ]%, scope=[1, 3, 5, 9, 11, 19]

--Search with transformer--
CUDA_VISIBLE_DEVICES=1 OMP_NUM_THREADS=12 python sp_train_context_240_seq5_win1_ovrp05_zr_inmask_multi_loss_c1z0s1-1010_lamb.py exp_context_240_seq5_win1_ovrp05_zr_inmask_multi_loss_c1z0s1-1010_lamb '100' test_sc3


@author: skchang@cochlear.ai
"""
#%%
import sys, glob, os
import numpy as np
import tensorflow as tf
from datetime import datetime
from EATS import generator_fp_dm as generator_fp
from EATS.networks.kapre2keras.melspectrogram import Melspectrogram
from utils.plotter import save_imshow, get_imshow_image
from utils.config_gpu_memory_lim import allow_gpu_memory_growth, config_gpu_memory_limit
from model.nnfp_context import FingerPrinter
from model.UnitB_seq_contrastive_loss_center_only import ContextContrastiveLoss
#from model.online_NTxent_variant_loss import OnlineNTxentVariantLoss
#from model.online_triplet_v2_fixed import Online_Batch_Triplet_Loss
from utils.eval_metric import eval_mini 
allow_gpu_memory_growth() #config_gpu_memory_limit(9)#  # GPU config: This is required if target GPU has smaller vmemory
from model.lamb_optimizer import LAMB
# from tensorflow_addons.optimizers.lamb import LAMB
from model.spec_augments.specaug_chain import SpecAugChainer
from eval_faiss import eval

# Context loss parameters
CONTEXT_MODE = 'bidirectional'
ADD_ZR_NEGATIVE = False
WEIGHT_MULTI_LOSS = [1., 1.] # [context_loss, simclr_loss]

# Transformer-parameters
H_INPUT_MASK = True
H_USE_CAUSAL_MASK = False # not implemented yet
H_NUM_LAYERS = 8 # number of transformer layers
H_NUM_HEADS = 4
H_DIM_FFN = 512 # dimension of feed-forward net
H_MAX_POS_ENC = 5 # int(SEQ_SAMPLING_DUR / SEG_HOP) - 1

# NTxent-parameters
TAU = 0.05 # 0.1 #1. #0.3
SAVE_IMG = False
OPTIMIZER = LAMB #tf.keras.optimizers.Adam
LR = 1e-4#5e-5#3e-5  #2e-5
LR_SCHEDULE = 'cos'

# Hyper-parameters
SEQ_SCOPE_SEC = 3.072 # sec
SEQ_SAMPLING_DUR = 3.072#10.
SEQ_SAMPLING_HOP = 0.512
SEQ_SAMPLING_OFFSET_HOP_RATE = 0.4 # rand. offset +-(hop/2)
SEG_WIN = 1.024 # sec
SEG_HOP = 0.512 # sec
EMB_SZ = 128  #256 not-working now..

TR_BATCH_SZ = 240
TR_N_ANCHOR = 120 #120 #64 #16  # 8
#---------------------------------------
VAL_BATCH_SZ = 60
VAL_N_ANCHOR = 30
TS_BATCH_SZ = 320 #160 #160
TS_N_ANCHOR = 160 #32 #80
MAX_EPOCH = 100
FEAT = 'melspec'  # 'spec' or 'melspec'
FS = 8000
EPOCH = ''
TEST_MODE = ''
SEG_WIN_FRAME = int(SEG_WIN * FS)
SEG_HOP_FRAME = int(SEG_HOP * FS)


# Specaug parameters
USE_SPECAUG = True
SPECAUG_CHAIN = ['cutout', 'horizontal']
SPECAUG_PROBS = 1
SPECAUG_N_HOLES = 1
SPECAUG_HOLE_FILL = 'zeros'

# Generating Embedding 
GEN_EMB_DATASEL = '10k' # '10k' '100k_full'

# Directories
DATA_ROOT_DIR = '../fingerprint_dataset/music/'
AUG_ROOT_DIR = '../fingerprint_dataset/aug/'
IR_ROOT_DIR = '../fingerprint_dataset/ir/'
SPEECH_ROOT_DIR = '../fingerprint_dataset/speech/common_voice_8k/en/'

music_fps = sorted(glob.glob(DATA_ROOT_DIR + '**/*.wav', recursive=True))
aug_tr_fps = sorted(glob.glob(AUG_ROOT_DIR + 'tr/**/*.wav', recursive=True))
aug_ts_fps = sorted(glob.glob(AUG_ROOT_DIR + 'ts/**/*.wav', recursive=True))
ir_fps = sorted(glob.glob(IR_ROOT_DIR + '**/*.wav', recursive=True))

speech_tr_fps = sorted(glob.glob(SPEECH_ROOT_DIR + 'train/**.wav', recursive=True))
speech_ts_fps = sorted(glob.glob(SPEECH_ROOT_DIR + 'test/**.wav', recursive=True))
#%%
#EXP_NAME = 'exp_NTxent_simCLR_use_anc_rep_120_tau0p05'
#EPOCH = 39
TEST_MODE = 'mini-test'


if len(sys.argv) > 1:
    EXP_NAME = sys.argv[1]
if len(sys.argv) > 2:
    EPOCH = sys.argv[2]
if len(sys.argv) == 1:
    EXP_NAME = datetime.now().strftime("%Y%m%d-%H%M")
if len(sys.argv) > 3:
    TEST_MODE = sys.argv[3]
if len(sys.argv) > 4:
    GEN_EMB_DATASEL = sys.argv[4]
#%%
CHECKPOINT_SAVE_DIR = './logs/checkpoint/{}/'.format(EXP_NAME)
CHECKPOINT_N_HOUR = 1  # None: disable
LOG_DIR = "logs/fit/" + EXP_NAME
IMG_DIR = 'logs/images/' + EXP_NAME
EMB_DIR = 'logs/emb/' + EXP_NAME
os.makedirs(IMG_DIR, exist_ok=True)
os.makedirs(EMB_DIR, exist_ok=True)

# Dataloader
def get_train_ds():
    ds = generator_fp.genUnbalSequence(
        fns_event_list=music_fps[:8500],
        bsz=TR_BATCH_SZ,
        n_anchor= TR_N_ANCHOR, #ex) bsz=40, n_anchor=8: 4 positive samples per anchor 
        duration=SEQ_SAMPLING_DUR,  # duration in seconds
        hop=SEQ_SAMPLING_HOP,
        fs=FS,
        shuffle=True,
        random_offset=True,
        offset_margin_hop_rate=SEQ_SAMPLING_OFFSET_HOP_RATE, # This will allow +- 50% randomness to offset
        bg_mix_parameter=[True, aug_tr_fps, (10, 10)],
        ir_mix_parameter=[True, ir_fps],
        speech_mix_parameter=[True, speech_tr_fps, (-10,10)]) #True, speech_tr_fps, (10,10)])
    return ds

def get_val_ds():
    ds = generator_fp.genUnbalSequence(
        music_fps[8500:],
        VAL_BATCH_SZ,
        VAL_N_ANCHOR,
        SEQ_SAMPLING_DUR,
        SEQ_SAMPLING_HOP,
        FS,
        shuffle=False,
        random_offset=False,
        bg_mix_parameter=[True, aug_ts_fps, (10, 10)],
        ir_mix_parameter=[True, ir_fps],
        speech_mix_parameter=[True, speech_tr_fps, (0,10)]) #[True, speech_tr_fps, (10,10)])
    return ds

def get_test_ds(no_aug=False):
    if GEN_EMB_DATASEL == '100k':
        test_dir = '../fingerprint_dataset/music_100k/'
    elif GEN_EMB_DATASEL == '100k_full':
        test_dir = '../fingerprint_dataset/music_100k_full/'
    elif GEN_EMB_DATASEL == '10k':
        test_dir = '../fingerprint_dataset/music/'
    
    test_fps = sorted(glob.glob(test_dir + '**/*.wav', recursive=True))
    if GEN_EMB_DATASEL == '10k':
        test_fps = test_fps[1000:]
    
    if no_aug:
        ds = generator_fp.genUnbalSequence(
            list(reversed(test_fps)), # reversed list for later on evaluation!!
            TS_BATCH_SZ, TS_BATCH_SZ, SEG_WIN, SEG_HOP, FS, shuffle=False, random_offset=False) 
    else:
        ds = generator_fp.genUnbalSequence(
            list(reversed(test_fps)), # reversed list for later on evaluation!!
            TS_BATCH_SZ,
            TS_N_ANCHOR,
            SEG_WIN,
            SEG_HOP,
            FS,
            shuffle=False,
            random_offset=False,
            bg_mix_parameter=[True, aug_ts_fps, (10, 10)],
            ir_mix_parameter=[True, ir_fps],
            speech_mix_parameter=[True, speech_ts_fps, (10,10)]
            )
    return ds

# Define Metric, Summary Log
tr_loss1 = tf.keras.metrics.Mean(name='train_loss1')
tr_loss2 = tf.keras.metrics.Mean(name='train_loss2')
tr_loss = tf.keras.metrics.Mean(name='train_loss')
tr_summary_writer_dict = dict()
for key in ['loss1', 'loss2', 'loss']: 
    tr_summary_writer_dict[key] = tf.summary.create_file_writer(LOG_DIR + '/train/' + key)

val_loss = tf.keras.metrics.Mean(name='val_loss')
val_summary_writer = tf.summary.create_file_writer(LOG_DIR + '/val')

ts_summary_writer_dict = dict()
for key in ['gf', 'f', 'f_postL2']: 
    ts_summary_writer_dict[key] = tf.summary.create_file_writer(LOG_DIR + '/mini_test/' + key)
image_writer = tf.summary.create_file_writer(LOG_DIR + '/images')

# Build Model: m_pre, m_fp, m_specaug
input_aud = tf.keras.Input(shape=(1, int(FS * SEG_WIN)))
mel = Melspectrogram(
    n_dft=1024,
    n_hop=256,
    sr=FS,
    n_mels=256,
    fmin=300,
    fmax=4000,
    return_decibel_melgram=True)(input_aud)
m_pre = tf.keras.Model(inputs=[input_aud], outputs=[mel])
m_pre.trainable = False
m_specaug = SpecAugChainer(chain_config=SPECAUG_CHAIN, probs=SPECAUG_PROBS,
                           n_holes=SPECAUG_N_HOLES, hole_fill=SPECAUG_HOLE_FILL)
assert(m_specaug.bypass==False)
m_specaug.trainable = False

m_fp = FingerPrinter(emb_sz=EMB_SZ,
                     h_input_mask=H_INPUT_MASK,
                     h_use_causal_mask=H_USE_CAUSAL_MASK,
                     h_num_heads=H_NUM_HEADS,
                     h_dff=H_DIM_FFN,  # d of FFN
                     h_max_pos_enc=H_MAX_POS_ENC)

# Define Optimizer & Loss
if LR_SCHEDULE == 'cos':
    lr_schedule = tf.keras.experimental.CosineDecay(initial_learning_rate=LR,
        decay_steps=len(get_train_ds()) * MAX_EPOCH, alpha=1e-07)
    opt = OPTIMIZER(learning_rate=lr_schedule)
elif LR_SCHEDULE == 'cos-restart':
    lr_schedule = tf.keras.experimental.CosineDecayRestarts(initial_learning_rate=LR,
        first_decay_steps=len(int(get_train_ds())*0.1), num_periods=0.5, alpha=2e-07)
    opt = OPTIMIZER(learning_rate=lr_schedule)
else:
    opt = OPTIMIZER(learning_rate=LR)
TR_N_REP = TR_BATCH_SZ - TR_N_ANCHOR
assert(TR_N_REP==TR_N_ANCHOR)

# Define loss function
Context_loss_tr = ContextContrastiveLoss(
    context_mode=CONTEXT_MODE,
    add_mirror_sim=ADD_ZR_NEGATIVE,
    τ=TAU,
    seg_scope=int(SEQ_SCOPE_SEC / SEG_HOP)-1,
    b_seq=TR_BATCH_SZ,
    b_seg=int(SEQ_SAMPLING_DUR / SEG_HOP)-1,
    weight_context_simclr_loss=WEIGHT_MULTI_LOSS)

loss_obj_tr = Context_loss_tr.compute_loss


VAL_N_REP = VAL_BATCH_SZ - VAL_N_ANCHOR
assert(VAL_N_REP==VAL_N_ANCHOR)
Context_loss_val = ContextContrastiveLoss(
    context_mode=CONTEXT_MODE,
    add_mirror_sim=ADD_ZR_NEGATIVE,
    τ=TAU,
    seg_scope=int(SEQ_SCOPE_SEC / SEG_HOP)-1,
    b_seq=VAL_BATCH_SZ,
    b_seg=int(SEQ_SAMPLING_DUR / SEG_HOP)-1,
    weight_context_simclr_loss=WEIGHT_MULTI_LOSS)

loss_obj_val = Context_loss_val.compute_loss

# Chekcpoint manager
checkpoint = tf.train.Checkpoint(optimizer=opt, model=m_fp)
c_manager = tf.train.CheckpointManager(checkpoint, CHECKPOINT_SAVE_DIR, 3,
                                       CHECKPOINT_N_HOUR)

if EPOCH == '':
    if c_manager.latest_checkpoint:
        tf.print("-----------Restoring from {}-----------".format(
            c_manager.latest_checkpoint))
        checkpoint.restore(c_manager.latest_checkpoint)
        EPOCH = c_manager.latest_checkpoint.split(sep='ckpt-')[-1]
    else:
        tf.print("-----------Initializing from scratch-----------")
else:    
    checkpoint_fname = CHECKPOINT_SAVE_DIR + 'ckpt-' + str(EPOCH)
    tf.print("-----------Restoring from {}-----------".format(checkpoint_fname))
    checkpoint.restore(checkpoint_fname)
    

@tf.function
def parallel_m_pre_specaug_from_audio_sequence(v, apply_specaug=True):
    """Method for slicing sequence into segment and extract mel-spec and
       repack as (Bseq, Bseg, F, T, 1)""" 
    # Input_wav: (Bseq, 1, T)
    b_seq = tf.shape(v)[0] # number of sequences
    v = tf.signal.frame(v, SEG_WIN_FRAME, SEG_HOP_FRAME, pad_end=False, axis=2)
    b_seg = tf.shape(v)[2] # means number of segments_per each sequence
    v = tf.reshape(v, (b_seq*b_seg, 1 , SEG_WIN_FRAME)) # (B,1,T_unit) with T_unit is unit-segment length
    
    # Apply m_pre --> repack melspecs
    v = m_pre(v) # (B,F,T_unitspec) with T_unitspec is unit-segment length in spectrogram
    if apply_specaug:
        v = m_specaug(v)
    dw, dh = tf.shape(v)[1], tf.shape(v)[2] # [n_mel, n_frame] of unit mel-spec segment
    return tf.reshape(v, (b_seq, b_seg, dw, dh, 1)) # Output: (B_seq, B_seg, F, T, 1)  

# with ts_summary_writer_dict[key].as_default():
#     for acc, scope in list(zip(accs_by_scope[0], scopes)): # [0] is top1_acc
#         tf.summary.scalar(f'acc_{scope}s', acc, step=opt.iterations)
# Trainer
@tf.function
def train_step(Xa, Xp):
    """Train step. Argument: {Xa: input_anchor, Xp: input_positive}."""
    X = tf.concat((Xa, Xp), axis=0) # (B_seq, 1, t_raw)
    feat = parallel_m_pre_specaug_from_audio_sequence(X, USE_SPECAUG) # (B_seqA+B_seqP, B_seg, F, T, 1)
    
    m_fp.trainable = True
    with tf.GradientTape() as t:
        emb_z, emb_c = m_fp(feat, apply_L2=True)  # (B_seq, B_seg, D)
        loss_context, loss_simclr = loss_obj_tr(emb_z, emb_c)
        loss = loss_context + loss_simclr
        sim_mtx = None

    g = t.gradient(loss, m_fp.trainable_variables)
    opt.apply_gradients(zip(g, m_fp.trainable_variables))
    
    # Logging
    tr_loss1(loss_context); tr_loss2(loss_simclr); tr_loss(loss)
    with tr_summary_writer_dict['loss1'].as_default():
        tf.summary.scalar('loss1', tr_loss1.result(), step=opt.iterations)
    with tr_summary_writer_dict['loss2'].as_default():
        tf.summary.scalar('loss2', tr_loss2.result(), step=opt.iterations)
    with tr_summary_writer_dict['loss'].as_default():
        tf.summary.scalar('loss', tr_loss.result(), step=opt.iterations)
    return sim_mtx


@tf.function
def val_step(Xa, Xp):
    """Validation step."""
    X = tf.concat((Xa, Xp), axis=0)
    feat = parallel_m_pre_specaug_from_audio_sequence(X, apply_specaug=False)
    
    m_fp.trainable = False
    emb_z, emb_c = m_fp(feat, apply_L2=True)  # (B_seq, B_seg, D)
    loss_context, loss_simclr = loss_obj_val(emb_z, emb_c)
    loss = loss_context + loss_simclr
    sim_mtx = None
    
    # Logging
    val_loss(loss)
    with val_summary_writer.as_default():
        tf.summary.scalar('loss', val_loss.result(), step=opt.iterations)
    return sim_mtx


@tf.function
def test_step(Xa, Xp, drop_div_enc=False):
    """Test step."""
    X = tf.concat((Xa, Xp), axis=0) # NOTE: X is (Bseg, 1, T) as in Unit A dataloader. 20.10.29
    feat = m_pre(X)
    
    m_fp.trainable = False
    if drop_div_enc:
        emb = m_fp.local_fp.front_conv(feat)  # Use f(x) as embedding:20.04.16.
    else:
        emb = m_fp.local_fp(feat, apply_L2=True) # Use g(f(x))
    return tf.split(emb, [TS_N_ANCHOR, TS_BATCH_SZ - TS_N_ANCHOR], axis=0)  # emb_Anchor, emb_Pos

#%% test functions...
def generate_emb(n_query=300000):
    """
    Arguemnts:
        n_query: Number of embeddings for queries. If 0, then save only DB.
        data_sel: Selecting dataset {'fma10k', 'fma100k', 'fma100kfull'}
    
    Output Numpy memmap-files:
        logs/emb/<exp_name>/db.mm: (float32) tensor of shape (nFingerPrints, dim)
        logs/emb/<exp_name>/query.mm: (float32) tensor of shape (nFingerprints, nAugments, dim)
        logs/emb/<exp_name>/db_shape.npy: (int) 
        logs/emb/<exp_name>/query_shape.npy: (int)
    
    """
    test_db_ds = get_test_ds(no_aug=True)
    test_query_ds = get_test_ds()
    n_augs_per_anchor = int((TS_BATCH_SZ - TS_N_ANCHOR) / TS_N_ANCHOR)
    n_augs_per_batch = n_augs_per_anchor * TS_N_ANCHOR
    n_query = (n_query // n_augs_per_batch) * n_augs_per_batch 
    n_batch_required_for_queries = int(n_query / n_augs_per_batch)
    shape_db = (len(test_db_ds) * TS_BATCH_SZ, EMB_SZ)
    shape_query = (n_query // n_augs_per_anchor, n_augs_per_anchor, EMB_SZ)

    # Create memmap, and save shapes
    output_dir = EMB_DIR + '/{}'.format(EPOCH) + '/' + GEN_EMB_DATASEL
    os.makedirs(output_dir, exist_ok=True)
    db = np.memmap(output_dir + '/db.mm', dtype='float32', mode='w+', shape=shape_db)
    np.save(output_dir + '/db_shape.npy', shape_db)
    if (n_query > 0):
        query = np.memmap(output_dir + '/query.mm', dtype='float32', mode='w+', shape=shape_query)
        np.save(output_dir + '/query_shape.npy', shape_query)
    
    # Generate Query
    print('-------Generating queries---------')
    progbar = tf.keras.utils.Progbar(n_batch_required_for_queries)
    enq = tf.keras.utils.OrderedEnqueuer(test_query_ds, use_multiprocessing=True, shuffle=False)
    enq.start(workers=8, max_queue_size=20)
    i = 0
    while (i < n_batch_required_for_queries) & (n_query != 0):
        progbar.update(i)
        Xa, Xp = next(enq.get()) 
        _, emb_pos = test_step(Xa, Xp)
        emb_pos = tf.reshape(emb_pos,
                             (TS_N_ANCHOR, n_augs_per_anchor, EMB_SZ))  # (B,4,128)
        query[i*TS_N_ANCHOR:(i+1)*TS_N_ANCHOR, :, : ] = emb_pos.numpy()
        i += 1
    enq.stop()
    
    # Generate DB
    print('-------Generating DB---------')
    progbar = tf.keras.utils.Progbar(len(test_db_ds))
    enq = tf.keras.utils.OrderedEnqueuer(test_db_ds, use_multiprocessing=True, shuffle=False)
    enq.start(workers=8, max_queue_size=20)
    i = 0
    while i < len(enq.sequence):
        progbar.update(i)
        Xa, Xp = next(enq.get()) 
        emb = tf.concat(test_step(Xa, Xp), axis=0)
        db[i*TS_BATCH_SZ:(i+1)*TS_BATCH_SZ, :] = emb.numpy()
        i += 1
    enq.stop()
    tf.print('------Succesfully saved embeddings to {}-----'.format(output_dir))
    del(db) # close mmap-files
    if (n_query > 0): del(query)
    return


def generate_emb_mirex():
    from utils.testset_file_manager import get_fns_from_txt
    MIREX_DB_INFO = '../fingerprint_dataset/split_info/mirex_ordered_db.txt'
    MIREX_QUERY_INFO = '../fingerprint_dataset/split_info/mirex_ordered_query.txt'
    BSZ_MIREX = 320
    ds_db = generator_fp.genUnbalSequence(get_fns_from_txt(MIREX_DB_INFO),
                                          BSZ_MIREX, BSZ_MIREX, SEG_WIN, SEG_HOP, FS,
                                          shuffle=False, random_offset=False)
    ds_query = generator_fp.genUnbalSequence(get_fns_from_txt(MIREX_QUERY_INFO),
                                          BSZ_MIREX, BSZ_MIREX, SEG_WIN, SEG_HOP, FS,
                                          shuffle=False, random_offset=False)
    db, query = np.empty(0), np.empty(0)
    m_fp.trainale = False

    progbar = tf.keras.utils.Progbar(len(ds_db))
    for i, (Xa, _) in enumerate(ds_db):
        progbar.update(i)
        emb = tf.concat(test_step(Xa, _), axis=0)
        db = np.concatenate((db, emb.numpy()), axis=0) if db.size else emb.numpy()
    
    progbar = tf.keras.utils.Progbar(len(ds_query))
    for i, (Xa, _) in enumerate(ds_query):
        progbar.update(i)
        emb = tf.concat(test_step(Xa, _), axis=0)
        query = np.concatenate((query, emb.numpy()), axis=0) if query.size else emb.numpy()
    
    output_dir = EMB_DIR + '/{}'.format(EPOCH)
    os.makedirs(output_dir, exist_ok=True)
    np.save(output_dir + '/MIREX_db.npy', db)
    np.save(output_dir + '/MIREX_query.npy', query)
    print(f'Succesfully finshed generating embeddings for MIREX DB and Queries...\n')
    return


def mini_search_test(mode='argmin', sel_emb='f', post_L2=False,
                     scopes=[1, 3, 5, 9, 11, 19], save=False, n_samples=3000):
    """Mini search test.
    - mode:'argmin' or 'argmax'
    - sel_emb: 'gf' uses g(f(.)) as embedding. 'f' uses f(.) as embedding.
    """
    test_ds = get_test_ds()
    if sel_emb=='gf':
        drop_div_enc = False
    elif sel_emb=='f':
        drop_div_enc = True
    else:
        raise NotImplementedError(sel_emb)
    
    # Collect mini DB
    db, query = np.empty(0), np.empty(0)
    n_iter = n_samples // TS_BATCH_SZ
    for i in range(n_iter):
        Xa, Xp = test_ds.__getitem__(i)
        emb_anc, emb_pos = test_step(Xa, Xp, drop_div_enc)
        # Post L2 normalize
        if post_L2:
            emb_anc = tf.math.l2_normalize(emb_anc, axis=-1)
            emb_pos = tf.math.l2_normalize(emb_pos, axis=-1)
        emb_pos = tf.reshape(emb_pos, (TS_N_ANCHOR, -1, emb_pos.shape[-1])) # (nAnc, nExam, dEmb)
        db = np.concatenate((db, emb_anc.numpy()), axis=0) if db.size else emb_anc.numpy()
        query = np.concatenate((query, emb_pos.numpy()), axis=0) if query.size else emb_pos.numpy()
    
    # Search test
    accs_by_scope, avg_rank_by_scope = eval_mini(query, db, mode=mode, display=True)
    # Write search test result
    if save:
        key = sel_emb + ('_postL2' if post_L2==True else '')
        with ts_summary_writer_dict[key].as_default():
            for acc, scope in list(zip(accs_by_scope[0], scopes)): # [0] is top1_acc
                tf.summary.scalar(f'acc_{scope}s', acc, step=opt.iterations)
    return


# Main loop
def main():
    if TEST_MODE == 'mini-test-only':
        tf.print('---------ArgMin g(f(x)) mini-TEST----------')
        mini_search_test(sel_emb='gf') # In-memory-search-test...
        tf.print('-----------ArgMin f(x) mini-TEST-----------')
        mini_search_test(sel_emb='f', post_L2=False)
        tf.print('---------ArgMin l2(f(x)) mini-TEST---------')     
        mini_search_test(sel_emb='f', post_L2=True)
    elif TEST_MODE == 'save-db':
        generate_emb(n_query=0)
    elif TEST_MODE == 'save-db-query':
        generate_emb_mirex()
        generate_emb(n_query=300000)
    elif TEST_MODE == 'test_sc3':
        m_fp.trainable = False
        emb_dir = 'logs/emb/exp_context_240_seq5_win1_ovrp05_zr_inmask_multi_loss_c1z0s1-1010_lamb/100/10k'
        eval(use_gpu=True, emb_dir=emb_dir, n_sample_test=2000, mode='ivfpq-rr',
             n_probe = 20, display_interval=10, test_mirex_query=True,
             scope=[3], transformer=m_fp) # 10k mirex test
        eval(use_gpu=True, emb_dir=emb_dir, n_sample_test=2000, mode='ivfpq-rr',
             n_probe = 20, display_interval=10, test_mirex_query=False,
             scope=[3], transformer=m_fp) # 10k mirex test
        eval(use_gpu=True, emb_dir=emb_dir, n_sample_test=2000, mode='ivfpq-rr',
             n_probe = 100, display_interval=10, test_mirex_query=True,
             scope=[3], transformer=m_fp) # 10k mirex test
        eval(use_gpu=True, emb_dir=emb_dir, n_sample_test=2000, mode='ivfpq-rr',
             n_probe = 100, display_interval=10, test_mirex_query=False,
             scope=[3], transformer=m_fp) # 10k mirex test
        
        emb_dir = 'logs/emb/exp_context_240_seq5_win1_ovrp05_zr_inmask_multi_loss_c1z0s1-1010_lamb/100/100k_full'
        eval(use_gpu=True, emb_dir=emb_dir, n_sample_test=2000, mode='ivfpq-rr',
             n_probe = 20, display_interval=10, test_mirex_query=False,
             scope=[3], transformer=m_fp) # 10k mirex test
        eval(use_gpu=True, emb_dir=emb_dir, n_sample_test=2000, mode='ivfpq-rr',
             n_probe = 100, display_interval=10, test_mirex_query=False,
             scope=[3], transformer=m_fp) # 10k mirex test
    else:
        n_iters = len(get_train_ds())
        start_ep = int(opt.iterations) // n_iters
        
        for ep in range(start_ep, MAX_EPOCH):
            tr_loss1.reset_states()
            tr_loss2.reset_states()
            tr_loss.reset_states()
            val_loss.reset_states()
            tf.print('EPOCH: {}/{}'.format(ep, MAX_EPOCH))
            progbar = tf.keras.utils.Progbar(n_iters)
    
            # Train
            """Parallelism to speed up preprocessing (2020-04-15)."""
            train_ds = get_train_ds()
            enq = tf.keras.utils.OrderedEnqueuer(train_ds, use_multiprocessing=True, shuffle=train_ds.shuffle)
            enq.start(workers=8, max_queue_size=20)

            i = opt.iterations.numpy() % n_iters # 0 unless using last checkpoint
            progbar.add(i)
            while i < len(enq.sequence):
                i += 1
                Xa, Xp = next(enq.get()) # For each, (Bseq, 1, t_raw)
                sim_mtx = train_step(Xa, Xp)
                progbar.add(1, values=[("tr loss1", tr_loss1.result()), ("tr loss2", tr_loss2.result()), ("tr loss", tr_loss.result())])
                """Required for breaking enqueue."""
            enq.stop()
            """End of Parallelism................................."""
            if SAVE_IMG:
                img_sim_mtx = get_imshow_image(sim_mtx.numpy(), f'Epoch={ep}')
                img_softmax_mtx = get_imshow_image(tf.nn.softmax(sim_mtx,
                    axis=1).numpy(), title=f'Epoch={ep}')
                with image_writer.as_default():
                    tf.summary.image('tr_sim_mtx', img_sim_mtx, step=opt.iterations)
                    tf.summary.image('tr_softmax_mtx', img_softmax_mtx, step=opt.iterations)
            c_manager.save()  # Save checkpoint...
    
            # Validate
            for Xa, Xp in get_val_ds():
                sim_mtx = val_step(Xa, Xp)
            # Save image..
            if SAVE_IMG:
                img_sim_mtx = get_imshow_image(sim_mtx.numpy(), f'Epoch={ep}')
                img_softmax_mtx = get_imshow_image(tf.nn.softmax(sim_mtx,
                    axis=1).numpy(), title=f'Epoch={ep}')
                with image_writer.as_default():
                    tf.summary.image('val_sim_mtx', img_sim_mtx, step=opt.iterations)
                    tf.summary.image('val_softmax_mtx', img_softmax_mtx, step=opt.iterations)
                    
                
            tf.print('trloss1:{:.4f}, trloss2:{:.4f}, trloss:{:.4f}, valloss:{:.4f}'.format(tr_loss1.result(),
                                                                                            tr_loss2.result(),
                                                                                            tr_loss.result(),
                                                                                            val_loss.result()))
            
            # Test 
            if TEST_MODE == 'mini-test':
                tf.print('---------ArgMin g(f(x)) mini-TEST----------')
                mini_search_test(sel_emb='gf', save=True) # In-memory-search-test...
                tf.print('-----------ArgMin f(x) mini-TEST-----------')
                mini_search_test(sel_emb='f', post_L2=False, save=True) # In-memory-search-test...
                tf.print('---------ArgMin l2(f(x)) mini-TEST---------')     
                mini_search_test(sel_emb='f', post_L2=True, save=True) # In-memory-search-test...
        
        # Generate embeddings after finishing training...
        generate_emb_mirex()
        GEN_EMB_DATASEL = '10k'
        generate_emb(n_query=300000)
        GEN_EMB_DATASEL = '100k_full'
        generate_emb(n_query=300000)
    return


if __name__ == "__main__":
    main()
